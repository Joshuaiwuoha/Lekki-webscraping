{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshuaiwuoha/Lekki-webscraping/blob/main/Lekki_web_scraping_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8pSjy4cpaY1"
      },
      "source": [
        "## Web Scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUPhaArFqgeb"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-cEMA3Iq9Y2"
      },
      "outputs": [],
      "source": [
        "# List of URLs for property listings in Lekki, Lagos\n",
        "my_urls = ['https://www.propertypro.ng/property-for-rent/in/lagos/lekki','https://www.propertypro.ng/property-for-sale/in/lagos/lekki/']\n",
        "\n",
        "# Empty list to store the HTML content of the pages\n",
        "page_url = []\n",
        "\n",
        "for each in my_urls:\n",
        "  # Make a request to the URL and retrieve the HTML content\n",
        "  page_url.append(requests.get(each))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT0T9NM9tExu"
      },
      "outputs": [],
      "source": [
        "# Empty list to store the HTML content of the pages\n",
        "page_content = []\n",
        "\n",
        "# Iterate through each page URL\n",
        "for each in page_url:\n",
        "   # Retrieve the text content of the page and append it to page_content\n",
        "  page_content.append(each.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiD_drJcrVvf"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRN17DPwrqEK"
      },
      "outputs": [],
      "source": [
        "# Empty list to store BeautifulSoup objects\n",
        "doc = []\n",
        "# Iterate through each page content\n",
        "for each in page_content:\n",
        "# Parse the HTML content using BeautifulSoup and append the resulting object to doc\n",
        " doc.append(BeautifulSoup(each,'html.parser'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXl3-Of4vMtS"
      },
      "outputs": [],
      "source": [
        "# Empty list to store the number of pages for each BeautifulSoup object\n",
        "num_pages = []\n",
        "# Iterate through each BeautifulSoup object\n",
        "for each in doc:\n",
        "  # Extract total number of pages and listings per page\n",
        "  total_pages = int(each.find_all('div',class_ = 'property-number-left')[0].text.strip().split(' ')[-1])\n",
        "  listing_per_page = int(each.find_all('div',class_ = 'property-number-left')[0].text.strip().split(' ')[3])\n",
        "  # Calculate the number of pages and append it to num_pages\n",
        "  num_pages.append(int(total_pages/listing_per_page))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOvK7yumwEA-",
        "outputId": "58c1a3c0-53c7-434e-93da-5b3f109598b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[120, 307]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "num_pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5Orrqb70h-x"
      },
      "outputs": [],
      "source": [
        "# Common URL prefix\n",
        "suffix = 'https://www.propertypro.ng'\n",
        "\n",
        "# CSS class for navigation links\n",
        "nav_bar_class = 'page-link'\n",
        "\n",
        "#Initialize lists with the first pages of both URLs\n",
        "first_pages = [pages[0]]\n",
        "second_pages = [pages[1]]\n",
        "\n",
        "# Counter to keep track of which set of pages is being processed\n",
        "counter = 0\n",
        "\n",
        "\n",
        "# Iterate through pairs of URLs and corresponding number of pages\n",
        "for i,j in zip(my_urls,num_pages):\n",
        "\n",
        "  # Iterate through the pages for each URL\n",
        "  for k in range(j-1):\n",
        "    if counter == 0:\n",
        "      page_url = requests.get(first_pages[k],'html')\n",
        "    elif counter == 1:\n",
        "      page_url = requests.get(second_pages[k],'html')\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    # Get the HTML content of the page\n",
        "    page_content = page_url.text\n",
        "\n",
        "    # Parse the HTML content with BeautifulSoup\n",
        "    doc = BeautifulSoup(page_content,'html.parser')\n",
        "\n",
        "     # Find navigation tags for the next page\n",
        "    nav_tags = doc.find_all('a', class_ = nav_bar_class, alt = 'view next property page')\n",
        "\n",
        "\n",
        "    # Append the next page URL to the corresponding list\n",
        "    if counter == 0:\n",
        "        first_pages.append(suffix + nav_tags[0]['href'])\n",
        "    elif counter == 1:\n",
        "        second_pages.append(suffix + nav_tags[0]['href'])\n",
        "    else:\n",
        "        break\n",
        "\n",
        "\n",
        "  # Increment the counter to switch to the next set of pages\n",
        "  counter += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnEX3XV4Wpji",
        "outputId": "d8bf1bf2-f225-4908-d7da-22a86b06fe37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 307)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# return the length of the first_pages and second_pages\n",
        "len(first_pages),len(second_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPiWh5qk0iMU"
      },
      "outputs": [],
      "source": [
        "# List to store scraped property information\n",
        "prices = []            # Property prices\n",
        "location = []          # Property locations\n",
        "apartment_type = []    # Property types\n",
        "update = []            # Update status\n",
        "status = []            # Furnishing status\n",
        "baths = []             # Number of bathrooms\n",
        "toilets = []           # Number of toilets\n",
        "\n",
        "# CSS classes for different property attributes\n",
        "price_class = 'listings-price'            # CSS class for property prices\n",
        "location_class = 'single-room-text'       # CSS class for property locations\n",
        "apartment_class = 'listings-property-title2'  # CSS class for property types\n",
        "status_class = 'furnished-btn'            # CSS class for property status (furnished or not)\n",
        "update_class = 'single-room-text'         # CSS class for property update status\n",
        "\n",
        "\n",
        "def extract(webpages):\n",
        "   \"\"\"\n",
        "    Extracts property information from a list of webpages.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  # Loop through each webpage\n",
        "  for each in webpages:\n",
        "    # Make a request to the webpage and retrieve the HTML content\n",
        "    page_url = requests.get(each,'html')\n",
        "    page_content = page_url.text\n",
        "    doc = BeautifulSoup(page_content,'html.parser')\n",
        "\n",
        "    # Extract property prices\n",
        "    price_tag = doc.find_all('h3',class_ = price_class)\n",
        "    for each in price_tag:\n",
        "      prices.append(int(each.text.strip().split(' ')[1].split('/')[0].replace(',','')))\n",
        "\n",
        "\n",
        "    # Extract property locations\n",
        "    loc_tag = doc.find_all('div', class_ = location_class)\n",
        "    for each in loc_tag:\n",
        "      location.append(' '.join(each.text.split('\\n')[2].split(' ')[:]))\n",
        "\n",
        "    # Extract property types\n",
        "    apart_tag = doc.find_all('h3',class_ = apartment_class)\n",
        "    for each in apart_tag:\n",
        "      apartment_type.append(each.text)\n",
        "\n",
        "    # Extract property status\n",
        "    status_tag = doc.find_all('div', class_ = status_class)\n",
        "    for each in status_tag:\n",
        "      status.append(','.join(each.text.strip().split('\\n')))\n",
        "\n",
        "    # Extract property update status\n",
        "    update_tag = doc.find_all('div', class_ = update_class)\n",
        "    for each in update_tag:\n",
        "      update.append(each.text.strip().split('\\n')[6])\n",
        "\n",
        "    # Extract number of bathrooms and toilets\n",
        "    bed_toil = doc.find_all('div',class_ = 'fur-areea')\n",
        "    for i,j in enumerate(bed_toil):\n",
        "      baths.append(bed_toil[i].text.strip().split(\"\\n\")[1])\n",
        "      toilets.append(bed_toil[i].text.strip().split(\"\\n\")[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first page"
      ],
      "metadata": {
        "id": "zN-mlDhGtpWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract(first_pages)"
      ],
      "metadata": {
        "id": "nHFlvGS0DoZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udv4DdKvVJhn",
        "outputId": "b13d19d4-6566-44c4-e380-4b1ec5193ae5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 6240, 6000, 6240, 6240, 6240, 6240)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(prices),len(location),len(apartment_type),len(status),len(update),len(baths),len(toilets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSzPB9K_YYDy"
      },
      "outputs": [],
      "source": [
        "location = location[:6000]\n",
        "status = status[:6000]\n",
        "update = update[:6000]\n",
        "baths = baths[:6000]\n",
        "toilets = toilets[:6000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDunz8ay0iQL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "frame = {'location':location,'apartment_type': apartment_type,'baths': baths,'toilets': toilets, 'status':status,'last_updated':update,'price':prices}\n",
        "data_df = pd.DataFrame(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOa6SsH4ozmH"
      },
      "outputs": [],
      "source": [
        "data_df.to_csv('lekki rentals',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/lekki rentals').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KffLLkTvjeU",
        "outputId": "4fe81f93-8ab7-4978-fb5d-7f99fa172307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# second pages"
      ],
      "metadata": {
        "id": "pNtQKBcIMUqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract(second_pages)"
      ],
      "metadata": {
        "id": "ZFICk3geJTvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c2cc07-563f-43f0-dbc7-ecd7ab7d47ce",
        "id": "q32UoYaXJQwa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21100, 21944, 21100, 21944, 21944, 21944, 21944)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(prices),len(location),len(apartment_type),len(status),len(update),len(baths),len(toilets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VaKgQWDJQwf"
      },
      "outputs": [],
      "source": [
        "location = location[:21100]\n",
        "status = status[:21100]\n",
        "update = update[:21100]\n",
        "baths = baths[:21100]\n",
        "toilets = toilets[:21100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lC4vwQqJQwg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "frame = {'location':location,'apartment_type': apartment_type,'baths': baths,'toilets': toilets, 'status':status,'last_updated':update,'price':prices}\n",
        "data_df = pd.DataFrame(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Uy5i-WrJQwh"
      },
      "outputs": [],
      "source": [
        "data_df.to_csv('lekki sales',index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlnYt3lJAZPuYc12d8/1iX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}